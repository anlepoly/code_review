diff --git a/src/corelib/arch/qatomic_armv5.h b/src/corelib/arch/qatomic_armv5.h
index b3136fe..210fbc1 100644
--- a/src/corelib/arch/qatomic_armv5.h
+++ b/src/corelib/arch/qatomic_armv5.h
@@ -95,7 +95,8 @@ template <int size> struct QBasicAtomicOps: QGenericAtomicOps<QBasicAtomicOps<si
         kernel_dmb();
     }
 
-    static void orderedMemoryFence() { _q_dmb(); }
+    template <typename T>
+    static void orderedMemoryFence(const T &) { _q_dmb(); }
 
     template <typename T> static bool ref(T &_q_value);
     template <typename T> static bool deref(T &_q_value);
diff --git a/src/corelib/arch/qatomic_armv6.h b/src/corelib/arch/qatomic_armv6.h
index b290a6a..5bf7096 100644
--- a/src/corelib/arch/qatomic_armv6.h
+++ b/src/corelib/arch/qatomic_armv6.h
@@ -77,7 +77,8 @@ template<> struct QAtomicIntegerTraits<unsigned int> { enum { IsInteger = 1 }; }
 
 template <int size> struct QBasicAtomicOps: QGenericAtomicOps<QBasicAtomicOps<size> >
 {
-    static void orderedMemoryFence();
+    template <typename T>
+    static void orderedMemoryFence(const T &);
 
     static inline bool isReferenceCountingNative() { return true; }
     template <typename T> static bool ref(T &_q_value);
@@ -705,8 +706,8 @@ Q_INLINE_TEMPLATE T *QBasicAtomicPointer<T>::fetchAndAddRelaxed(qptrdiff valueTo
 
 // common code
 
-template <int size> inline
-void QBasicAtomicOps<size>::orderedMemoryFence()
+template <int size> template <typename T> inline
+void QBasicAtomicOps<size>::orderedMemoryFence(const T &)
 {
     Q_DATA_MEMORY_BARRIER;
 }
diff --git a/src/corelib/arch/qatomic_cxx11.h b/src/corelib/arch/qatomic_cxx11.h
index 27e0acd..ec6b3e3 100644
--- a/src/corelib/arch/qatomic_cxx11.h
+++ b/src/corelib/arch/qatomic_cxx11.h
@@ -108,10 +108,6 @@ template <typename T> struct QAtomicOps
     typedef typename QAtomicAdditiveType<T>::AdditiveT _AdditiveType;
     static const int AddScale = QAtomicAdditiveType<T>::AddScale;
 
-    static void acquireMemoryFence() { }
-    static void releaseMemoryFence() { }
-    static void orderedMemoryFence() { }
-
     static inline
     T load(const Type &_q_value)
     {
diff --git a/src/corelib/arch/qatomic_ia64.h b/src/corelib/arch/qatomic_ia64.h
index 5108751..a2bca55 100644
--- a/src/corelib/arch/qatomic_ia64.h
+++ b/src/corelib/arch/qatomic_ia64.h
@@ -140,7 +140,8 @@ template<> struct QAtomicIntegerTraits<unsigned long long> { enum { IsInteger =
 
 template <int size> struct QBasicAtomicOps: QGenericAtomicOps<QBasicAtomicOps<size> >
 {
-    static void orderedMemoryFence();
+    template <typename T>
+    static void orderedMemoryFence(const T &);
 
     template <typename T> static inline
     T loadAcquire(const T &_q_value)
@@ -202,8 +203,8 @@ inline bool _q_ia64_fetchadd_immediate(register int value)
 // intrinsics provided by the Intel C++ Compiler
 #include <ia64intrin.h>
 
-template<int size> inline
-void QBasicAtomicOps<size>::orderedMemoryFence()
+template<int size> template <typename T> inline
+void QBasicAtomicOps<size>::orderedMemoryFence(const T &)
 {
     __memory_barrier();
 }
@@ -332,8 +333,8 @@ Q_INLINE_TEMPLATE T *QBasicAtomicPointer<T>::fetchAndAddRelease(qptrdiff valueTo
 
 #elif defined(Q_CC_GNU)
 
-template<int size> inline
-void QBasicAtomicOps<size>::orderedMemoryFence()
+template<int size> template <typename T> inline
+void QBasicAtomicOps<size>::orderedMemoryFence(const T &)
 {
     asm volatile("mf" ::: "memory");
 }
@@ -1045,7 +1046,7 @@ bool QBasicAtomicOps<size>::testAndSetRelaxed(T &_q_value, T expectedValue, T ne
 template<int size> template <typename T> inline
 bool QBasicAtomicOps<size>::testAndSetOrdered(T &_q_value, T expectedValue, T newValue)
 {
-    orderedMemoryFence();
+    orderedMemoryFence(_q_value);
     return testAndSetAcquire(_q_value, expectedValue, newValue);
 }
 
@@ -1058,7 +1059,7 @@ T QBasicAtomicOps<size>::fetchAndStoreRelaxed(T &_q_value, T newValue)
 template<int size> template <typename T> inline
 T QBasicAtomicOps<size>::fetchAndStoreRelease(T &_q_value, T newValue)
 {
-    orderedMemoryFence();
+    orderedMemoryFence(_q_value);
     return fetchAndStoreAcquire(_q_value, newValue);
 }
 
@@ -1077,7 +1078,7 @@ T QBasicAtomicOps<size>::fetchAndAddRelaxed(T &_q_value, typename QAtomicAdditiv
 template<int size> template <typename T> inline
 T QBasicAtomicOps<size>::fetchAndAddOrdered(T &_q_value, typename QAtomicAdditiveType<T>::AdditiveT valueToAdd)
 {
-    orderedMemoryFence();
+    orderedMemoryFence(_q_value);
     return fetchAndAddRelease(_q_value, valueToAdd);
 }
 
diff --git a/src/corelib/arch/qatomic_mips.h b/src/corelib/arch/qatomic_mips.h
index 39119ba..116906a 100644
--- a/src/corelib/arch/qatomic_mips.h
+++ b/src/corelib/arch/qatomic_mips.h
@@ -77,9 +77,12 @@ template<> struct QAtomicIntegerTraits<unsigned int> { enum { IsInteger = 1 }; }
 
 template <int size> struct QBasicAtomicOps: QGenericAtomicOps<QBasicAtomicOps<size> >
 {
-    static void acquireMemoryFence();
-    static void releaseMemoryFence();
-    static void orderedMemoryFence();
+    template <typename T>
+    static void acquireMemoryFence(const T &);
+    template <typename T>
+    static void releaseMemoryFence(const T &);
+    template <typename T>
+    static void orderedMemoryFence(const T &);
 
     static inline bool isReferenceCountingNative() { return true; }
     template <typename T> static bool ref(T &_q_value);
@@ -109,20 +112,20 @@ template <typename T> struct QAtomicOps : QBasicAtomicOps<sizeof(T)>
 # error "please set '-march=' to your architecture (e.g., -march=mips32)"
 #endif
 
-template <int size> inline
-void QBasicAtomicOps<size>::acquireMemoryFence()
+template <int size> template <typename T> inline
+void QBasicAtomicOps<size>::acquireMemoryFence(const T &)
 {
     asm volatile ("sync 0x11" ::: "memory");
 }
 
-template <int size> inline
-void QBasicAtomicOps<size>::releaseMemoryFence()
+template <int size> template <typename T> inline
+void QBasicAtomicOps<size>::releaseMemoryFence(const T &)
 {
     asm volatile ("sync 0x12" ::: "memory");
 }
 
-template <int size> inline
-void QBasicAtomicOps<size>::orderedMemoryFence()
+template <int size> template <typename T> inline
+void QBasicAtomicOps<size>::orderedMemoryFence(const T &)
 {
     asm volatile ("sync 0" ::: "memory");
 }
diff --git a/src/corelib/thread/qgenericatomic.h b/src/corelib/thread/qgenericatomic.h
index 34c040c..c0e8252 100644
--- a/src/corelib/thread/qgenericatomic.h
+++ b/src/corelib/thread/qgenericatomic.h
@@ -80,9 +80,17 @@ template <typename BaseClass> struct QGenericAtomicOps
 {
     template <typename T> struct AtomicType { typedef T Type; typedef T *PointerType; };
 
-    static void acquireMemoryFence() { BaseClass::orderedMemoryFence(); }
-    static void releaseMemoryFence() { BaseClass::orderedMemoryFence(); }
-    static void orderedMemoryFence() { }
+    template <typename T> static void acquireMemoryFence(const T &_q_value)
+    {
+        BaseClass::orderedMemoryFence(_q_value);
+    }
+    template <typename T> static void releaseMemoryFence(const T &_q_value)
+    {
+        BaseClass::orderedMemoryFence(_q_value);
+    }
+    template <typename T> static void orderedMemoryFence(const T &)
+    {
+    }
 
     template <typename T> static inline always_inline
     T load(const T &_q_value)
@@ -100,14 +108,14 @@ template <typename BaseClass> struct QGenericAtomicOps
     T loadAcquire(const T &_q_value)
     {
         T tmp = *static_cast<const volatile T *>(&_q_value);
-        BaseClass::acquireMemoryFence();
+        BaseClass::acquireMemoryFence(_q_value);
         return tmp;
     }
 
     template <typename T, typename X> static inline always_inline
     void storeRelease(T &_q_value, X newValue)
     {
-        BaseClass::releaseMemoryFence();
+        BaseClass::releaseMemoryFence(_q_value);
         *static_cast<volatile T *>(&_q_value) = newValue;
     }
 
@@ -140,21 +148,21 @@ template <typename BaseClass> struct QGenericAtomicOps
     bool testAndSetAcquire(T &_q_value, X expectedValue, X newValue)
     {
         bool tmp = BaseClass::testAndSetRelaxed(_q_value, expectedValue, newValue);
-        BaseClass::acquireMemoryFence();
+        BaseClass::acquireMemoryFence(_q_value);
         return tmp;
     }
 
     template <typename T, typename X> static inline always_inline
     bool testAndSetRelease(T &_q_value, X expectedValue, X newValue)
     {
-        BaseClass::releaseMemoryFence();
+        BaseClass::releaseMemoryFence(_q_value);
         return BaseClass::testAndSetRelaxed(_q_value, expectedValue, newValue);
     }
 
     template <typename T, typename X> static inline always_inline
     bool testAndSetOrdered(T &_q_value, X expectedValue, X newValue)
     {
-        BaseClass::orderedMemoryFence();
+        BaseClass::orderedMemoryFence(_q_value);
         return BaseClass::testAndSetRelaxed(_q_value, expectedValue, newValue);
     }
 
@@ -176,21 +184,21 @@ template <typename BaseClass> struct QGenericAtomicOps
     T fetchAndStoreAcquire(T &_q_value, X newValue)
     {
         T tmp = BaseClass::fetchAndStoreRelaxed(_q_value, newValue);
-        BaseClass::acquireMemoryFence();
+        BaseClass::acquireMemoryFence(_q_value);
         return tmp;
     }
 
     template <typename T, typename X> static inline always_inline
     T fetchAndStoreRelease(T &_q_value, X newValue)
     {
-        BaseClass::releaseMemoryFence();
+        BaseClass::releaseMemoryFence(_q_value);
         return BaseClass::fetchAndStoreRelaxed(_q_value, newValue);
     }
 
     template <typename T, typename X> static inline always_inline
     T fetchAndStoreOrdered(T &_q_value, X newValue)
     {
-        BaseClass::orderedMemoryFence();
+        BaseClass::orderedMemoryFence(_q_value);
         return BaseClass::fetchAndStoreRelaxed(_q_value, newValue);
     }
 
@@ -211,21 +219,21 @@ template <typename BaseClass> struct QGenericAtomicOps
     T fetchAndAddAcquire(T &_q_value, typename QAtomicAdditiveType<T>::AdditiveT valueToAdd)
     {
         T tmp = BaseClass::fetchAndAddRelaxed(_q_value, valueToAdd);
-        BaseClass::acquireMemoryFence();
+        BaseClass::acquireMemoryFence(_q_value);
         return tmp;
     }
 
     template <typename T> static inline always_inline
     T fetchAndAddRelease(T &_q_value, typename QAtomicAdditiveType<T>::AdditiveT valueToAdd)
     {
-        BaseClass::releaseMemoryFence();
+        BaseClass::releaseMemoryFence(_q_value);
         return BaseClass::fetchAndAddRelaxed(_q_value, valueToAdd);
     }
 
     template <typename T> static inline always_inline
     T fetchAndAddOrdered(T &_q_value, typename QAtomicAdditiveType<T>::AdditiveT valueToAdd)
     {
-        BaseClass::orderedMemoryFence();
+        BaseClass::orderedMemoryFence(_q_value);
         return BaseClass::fetchAndAddRelaxed(_q_value, valueToAdd);
     }
 };